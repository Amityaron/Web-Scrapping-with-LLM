{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 text sentiment\n",
      "0   ח\"כ מילביצקי זומן לחקירה בלהב 433, החשד: עבירו...   neutral\n",
      "1    צה\"ל: כ-50 אזרחים ישראלים נכנסו במהלך הלילה לשכם   neutral\n",
      "2       עיריית הרצליה: חוף השרון בעיר נפתח מחדש לרחצה  negative\n",
      "3   רויטרס: ממשל טראמפ לא מצא ראיות לגניבה שיטתית ...   neutral\n",
      "4     צה\"ל: אלוף שי קלפר נכנס לתפקיד מפקד פיקוד העורף   neutral\n",
      "..                                                ...       ...\n",
      "95  אישום: נהגת חדשה גרמה למותן של שתי נוסעות, בהן...   neutral\n",
      "96  דיווחים: הרוגים ופצועים בתקיפת מחסן תחמושת וטי...  negative\n",
      "97  המתווך הפלסטיני-אמריקני בין ארה\"ב לחמאס: \"על י...  negative\n",
      "98  רפאל תקיים ניסוי בקריות בשעות הצהריים, עשוי לה...   neutral\n",
      "99  סוכנויות הידיעות המובילות פנו לישראל: לאפשר לע...   neutral\n",
      "\n",
      "[100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Dummy sentiment analysis function\n",
    "def analyze_sentiment(text):\n",
    "    text = text.strip()\n",
    "    if any(word in text for word in ['מת', 'נהרג', 'אסון', 'תאונה', 'פצוע', 'ירי', 'הרג']):\n",
    "        return 'negative'\n",
    "    elif any(word in text for word in ['נפתח', 'זכה', 'נבחר', 'חוגגים', 'שוחרר']):\n",
    "        return 'positive'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "# Set up headless browser\n",
    "options = Options()\n",
    "options.add_argument(\"--headless=new\")\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "# Launch Chrome\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "# Load the Ynet news page\n",
    "url = \"https://www.ynet.co.il/news/category/184\"\n",
    "driver.get(url)\n",
    "\n",
    "# Wait for JS to load\n",
    "time.sleep(5)\n",
    "\n",
    "# Parse the rendered HTML\n",
    "soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "driver.quit()\n",
    "\n",
    "# Extract breaking news headlines\n",
    "headlines = []\n",
    "for section in soup.find_all('div', class_='AccordionSection'):\n",
    "    title_tag = section.find('div', class_='title')\n",
    "    if title_tag:\n",
    "        text = title_tag.get_text(strip=True)\n",
    "        sentiment = analyze_sentiment(text)\n",
    "        headlines.append({'text': text, 'sentiment': sentiment})\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(headlines)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model sentiment based on LLM model from huggingface "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 text sentiment\n",
      "0             לפיד: \"מי שאחראי על הרעב בעזה הוא חמאס\"  negative\n",
      "1     דיווחים בלבנון: פצוע בתקיפת אופנוע בדרום המדינה  negative\n",
      "2   ראש אכ\"א נפגש עם נציגי מילואימניקים: בשנה הבאה...  negative\n",
      "3          3 לוחמי הנח\"ל שסירבו להיכנס לעזה לא ייאסרו  negative\n",
      "4              גרמניה תעביר אספקת סיוע מהאוויר לרצועה  positive\n",
      "..                                                ...       ...\n",
      "75  עקב תנאי מזג האוויר: עוצר אימונים בצה\"ל עד יום...  positive\n",
      "76   ארה\"ב תטיל מכסים בשיעור של 15% על האיחוד האירופי  negative\n",
      "77  נתניהו בוועידת הנצרות: \"אתם נלחמים לצידנו בחזי...  negative\n",
      "78  דיווח בבריטניה: הממשלה \"תדון במצב בעזה\", בצל ל...  negative\n",
      "79     פרשת \"קטאר-גייט\": בכיר לשעבר במוסד נחקר באזהרה  negative\n",
      "\n",
      "[80 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# ✅ Insert your Hugging Face API Token here\n",
    "HF_API_TOKEN = \"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\"  # ← replace this\n",
    "\n",
    "# ✅ Hugging Face inference API URL for multilingual sentiment model\n",
    "HF_API_URL =  \"https://api-inference.huggingface.co/models/nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "\n",
    "#\n",
    "# Sentiment analysis using Hugging Face API\n",
    "def analyze_sentiment(text):\n",
    "    headers = {\"Authorization\": \"Bearer \" + HF_API_TOKEN}\n",
    "    payload = {\"inputs\": text}\n",
    "\n",
    "    try:\n",
    "        response = requests.post(HF_API_URL, headers=headers, json=payload)\n",
    "        result = response.json()\n",
    "\n",
    "        # Debugging: show API output\n",
    "        #print(\"Text:\", text)\n",
    "        #print(\"Result:\", result)\n",
    "\n",
    "        if \"error\" in result:\n",
    "            return \"unknown\"\n",
    "\n",
    "        label = result[0][0]['label']  # e.g., \"4 stars\"\n",
    "        stars = int(label[0])\n",
    "\n",
    "        if stars <= 2:\n",
    "            return \"negative\"\n",
    "        elif stars == 3:\n",
    "            return \"neutral\"\n",
    "        else:\n",
    "            return \"positive\"\n",
    "    except Exception as e:\n",
    "        print(\"Exception:\", str(e))\n",
    "        return \"error\"\n",
    "\n",
    "# ✅ Set up headless Chrome browser\n",
    "options = Options()\n",
    "options.add_argument(\"--headless=new\")\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "# ✅ Open Ynet breaking news page\n",
    "url = \"https://www.ynet.co.il/news/category/184\"\n",
    "driver.get(url)\n",
    "time.sleep(5)  # Let JavaScript load\n",
    "\n",
    "# ✅ Parse HTML using BeautifulSoup\n",
    "soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "driver.quit()\n",
    "\n",
    "# ✅ Extract headlines and analyze sentiment\n",
    "headlines = []\n",
    "for section in soup.find_all('div', class_='AccordionSection'):\n",
    "    title_tag = section.find('div', class_='title')\n",
    "    if title_tag:\n",
    "        text = title_tag.get_text(strip=True)\n",
    "        sentiment = analyze_sentiment(text)\n",
    "        headlines.append({'text': text, 'sentiment': sentiment})\n",
    "\n",
    "# ✅ Convert to DataFrame\n",
    "df = pd.DataFrame(headlines)\n",
    "print(df)\n",
    "\n",
    "# Optional: Save to CSV\n",
    "#df.to_csv(\"ynet_headlines_sentiment.csv\", index=False, encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Verify that the Api working well "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "[[{'label': '1 star', 'score': 0.8551278710365295}, {'label': '2 stars', 'score': 0.0796511247754097}, {'label': '3 stars', 'score': 0.0329224169254303}, {'label': '5 stars', 'score': 0.020748702809214592}, {'label': '4 stars', 'score': 0.011549958027899265}]]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "headers = {\"Authorization\": \"Bearer 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\"}\n",
    "payload = {\"inputs\": \"זה יום נפלא בישראל\"}\n",
    "\n",
    "response = requests.post(\n",
    "    \"https://api-inference.huggingface.co/models/nlptown/bert-base-multilingual-uncased-sentiment\",\n",
    "    headers=headers,\n",
    "    json=payload\n",
    ")\n",
    "\n",
    "print(response.status_code)\n",
    "print(response.json())\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNKq0/2qlwTrjYG1ibzrb22",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
